{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Drug Sensitivity Prediction on CCLE\"\nauthor: \"Jens Hooge\"\ndate: \"9 3 2016\"\noutput: html_document\n---\n\nThe goal of this analysis is to build a predictive model for drug sensitivity prediction on the CCLE dataset. The response vector is split into two classes of responders and non responders. The features include discrete features (Mutations and Copy Numbers) as well as continuous features (Expression values)\n\n```{r Load Libraries}\nlibrary(stringr) ## string operations\nlibrary(caret) ## applied predictive models\nlibrary(doMC) ## library for multi-core processing\nlibrary(AppliedPredictiveModeling)\nlibrary(pROC)\n#library(corrplot)\nlibrary(fastICA)\nlibrary(rbokeh) # interactive plotting\n```\n\nFirst let's load the data:\n\n```{r setup, include=FALSE}\nload(\"/gpfs01/bhcbio/scratch/trainingData_DHODH.RData\")\nsource(\"~/workspace/R/sandbox/Visualization/mlDataExploration.R\")\n```\n\n## Data Exploration\n\n```{r Split data types}\nY <- as.factor(class.full)\nX_full <- FM.full\nX_CN   <- X_full[, grepl(\"CN.\" , names(X_full))]\nX_Expr <- X_full[, grepl(\"Expr.\" , names(X_full))]\nX_Mut  <- X_full[, grepl(\"Mut.\" , names(X_full))]\n  \n## Remove datatype identifiers from copynumber, expression and mutation matrix\ncolnames(X_CN) <- gsub(\"CN.\", \"\\\\1\", names(X_CN))\ncolnames(X_Expr) <- gsub(\"Expr.\", \"\\\\1\", names(X_Expr))\ncolnames(X_Mut) <- gsub(\"Mut.\", \"\\\\1\", names(X_Mut))\n\n## We will also replace all \".\" with \"_\" in the columnnames of each feature matrix \n## and the response vector, as this usually leads to problems in the train function of caret\nnames(Y) <- str_replace_all(names(Y), \"[.]\", \"_\")\ncolnames(X_CN) <- str_replace_all(colnames(X_CN), \"[.]\", \"_\")\ncolnames(X_Expr) <- str_replace_all(colnames(X_Expr), \"[.]\", \"_\")\ncolnames(X_Mut) <- str_replace_all(colnames(X_Mut), \"[.]\", \"_\")\n\n# Split label vector an feature matrix in labeled and unlabeled data\nisNA <- which(is.na(Y))\n\nY_labeled <- Y[-isNA]\nY_unlabeled <- Y[isNA]\n\nX_full_labled <- X_full[-isNA, ]\nX_CN_labled   <- X_CN[-isNA, ]\nX_Expr_labled <- X_Expr[-isNA, ]\nX_Mut_labled  <- X_Mut[-isNA,]\n\nX_full_unlabled <- X_full[isNA, ]\nX_CN_unlabled   <- X_CN[isNA, ]\nX_Expr_unlabled <- X_Expr[isNA, ]\nX_Mut_unlabled  <- X_Mut[isNA, ]\n\n# ## Remove highly correlated features\n# correlations <- cor(X_Expr_labled)\n# highCorr <- findCorrelation(correlations, cutoff=.75)\n# X_Expr_labled_filtered <- X_Expr_labled[, -highCorr]\n# correlations_filtered <- cor(X_Expr_labled_filtered)\n# corrplot(correlations_filtered, order = \"hclust\")\n\n\npcaTransform <- function(df) {\n  preProc      <- preProcess(df, method=c(\"pca\", \"center\", \"scale\" ))\n  transformed  <- predict(preProc, df)\n  return(transformed) \n}\n\nicaTransform <- function(df) {\n  preProc      <- preProcess(df, method=c(\"ica\", \"center\", \"scale\" ))\n  transformed  <- predict(preProc, df)\n  return(transformed) \n}\n\n#X_Expr_PCA <- pcaTransform(X_Expr)\n#X_Expr_ICA <- icaTransform(X_Expr)\n```\n\nWe have `r dim(X_full)[1]` samples and `r dim(X_full)[2]` genomic features, including `r dim(X_CN)[2]` copy number values, `r dim(X_Mut)[2]` mutations and `r dim(X_Expr)[2]` expression features.\n\n## Skewness\n### Expression Values\n```{r Expression Skewness}\nplotSkewness(X_Expr_labled)\n```\n\n## Dimensionality Reduction\nFirst we will have a look at two dimensionaliity reduction techniques, namely PCA and ICA and decide for the one, that shows better separability between responders and non-responders.\n\n### PCA \n```{r Dimensionality Reduction - PCA}\npreProcessing <- list(PCA=preProcess(X_Expr_labled, method=c(\"pca\", \"center\", \"scale\")),\n                      ICA=preProcess(X_Expr_labled, method=c(\"ica\", \"center\", \"scale\"), n.comp=50))\nX_Expr_labled_PCA <- predict(preProcessing$PCA, X_Expr_labled)\n\ndf <- X_Expr_labled_PCA\ndf$Label <- Y_labeled\n\ntools <- c(\"pan\", \n           \"wheel_zoom\", \"box_zoom\", \n           \"box_select\", \"lasso_select\", \n           \"reset\", \"save\")\nnms <- expand.grid(names(df)[1:3], \n                   rev(names(df)[1:3]),\n                       stringsAsFactors = FALSE)\n\nsplom_list <- vector(\"list\", 9)\nfor(ii in seq_len(nrow(nms))) {\n  splom_list[[ii]] <- figure(width = 200, height = 200, tools = tools,\n    xlab = nms$Var1[ii], ylab = nms$Var2[ii]) %>%\n    ly_points(nms$Var1[ii], nms$Var2[ii], data = df,\n      color = Label, size = 5, legend = FALSE)\n}\ngrid_plot(splom_list, ncol = 3, same_axes = TRUE, link_data = TRUE)\n\nfigure(tools=tools) %>%\n  ly_points(PC2, PC1, data = df,\n            color = Label)\n\nfigure(tools=tools) %>%\n  ly_points(PC3, PC1, data = df,\n            color = Label)\n\n```\n\n### ICA\n```{r Dimensionality Reduction - ICA}\nX_Expr_labled_ICA <- predict(preProcessing$ICA, X_Expr_labled)\n\ndf <- X_Expr_labled_ICA\ndf$Label <- Y_labeled\n\ntools <- c(\"pan\", \n           \"wheel_zoom\", \"box_zoom\", \n           \"box_select\", \"lasso_select\", \n           \"reset\", \"save\")\nnms <- expand.grid(names(df)[1:3], \n                   rev(names(df)[1:3]),\n                       stringsAsFactors = FALSE)\n\nsplom_list <- vector(\"list\", 9)\nfor(ii in seq_len(nrow(nms))) {\n  splom_list[[ii]] <- figure(width = 200, height = 200, tools = tools,\n    xlab = nms$Var1[ii], ylab = nms$Var2[ii]) %>%\n    ly_points(nms$Var1[ii], nms$Var2[ii], data = df,\n      color = Label, size = 5, legend = FALSE)\n}\ngrid_plot(splom_list, ncol = 3, same_axes = TRUE, link_data = TRUE)\n\nfigure(tools=tools) %>%\n  ly_points(ICA2, ICA1, data = df,\n            color = Label)\n\nfigure(tools=tools) %>%\n  ly_points(ICA3, ICA1, data = df,\n            color = Label)\n```\n\n\n\n## Train a simple model on expression values\n```{r Training on Expression Values}\nset.seed(42) ## Seed for reproducibility\n\n## Split data in crossvalidation datasets. 80% of the samples will be used for training\ntrainRows    <- createDataPartition(Y_labeled, p=.80, list=FALSE)\ntrainData    <- X_Expr_labled[trainRows, ]\ntestData     <- X_Expr_labled[-trainRows, ]\ntrainClasses <- Y_labeled[trainRows]\ntestClasses  <- Y_labeled[-trainRows]\n```\n\n```{r, Training Models}\n## Define Parameter grid for models used in this analysis\n# tuneGrids <- list(\n#   knn = expand.grid(k=1:20),\n#   nb = expand.grid(usekernel=TRUE, fL=seq(from=0, to=100, length=11)),\n#   svm = expand.grid(C=seq(1, 100, length=11))\n#   )\n# \n# ## The data will be centered and scaled, but we will apply\n# ## different dimensionality reduction techniques\n# \n# ## we will register 16 threads for the following computation\n# registerDoMC(16)\n# ctrl <- trainControl(\n#   method = \"repeatedcv\", ## k-fold Cross Validation\n#   number = 5, ## Number of folds\n#   repeats = 10, ## Number of repetitions for statistical stability\n#   summaryFunction = twoClassSummary, ## Return model performance for binary classification\n#   savePredictions = TRUE,\n#   classProbs = TRUE, ## Return class probabilities as well\n#   allowParallel = TRUE ## Use multiple CPUs\n# )\n# \n# knnModel <- train(trainData, trainClasses,\n#                   method = \"knn\",\n#                   metric = \"ROC\",\n#                   tuneGrid = tuneGrids$knn,\n#                   preProcess = c(\"pca\", \"center\", \"scale\"),\n#                   trControl = ctrl)\n# \n# nbModel <- train(trainData, trainClasses,\n#               method = \"nb\",\n#               metric = \"ROC\",\n#               tuneGrid = tuneGrids$nb,\n#               preProcess = c(\"pca\", \"center\", \"scale\"),\n#               trControl = ctrl)\n# \n# linSVM <- train(trainData, trainClasses,\n#                 method = \"svmLinear\",\n#                 metric = \"ROC\",\n#                 tuneGrid = tuneGrids$svm,\n#                 preProcess = c(\"pca\", \"center\", \"scale\"),\n#                 trControl = ctrl)\n# \n# models <- list(knn=knnModel,\n#                NaiveBayes=nbModel,\n#                LinearSVM=linSVM)\n```\n\n## Zero Variance Predictors\n",
    "created" : 1459924211634.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3745384132",
    "id" : "E583E50B",
    "lastKnownWriteTime" : 1458226187,
    "last_content_update" : 1458226187,
    "path" : "~/workspace/R/projects/CCLE_PredictiveModel/buildPredModel_DHODH.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}